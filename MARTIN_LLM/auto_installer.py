# -*- coding: utf-8 -*-
# auto_installer.py - Instalador automÃ¡tico de dependencias basado en hardware

import sys
import subprocess
import os
import platform
from pathlib import Path

class AutoInstaller:
    """Instala automÃ¡ticamente las dependencias correctas segÃºn el hardware."""
    
    def __init__(self):
        self.system = platform.system().lower()
        self.is_admin = self._check_admin_privileges()
        
    def _check_admin_privileges(self):
        """Verifica si se tiene privilegios de administrador."""
        try:
            if self.system == 'windows':
                import ctypes
                return ctypes.windll.shell32.IsUserAnAdmin()
            else:
                return os.geteuid() == 0
        except:
            return False
    
    def install_cuda_support(self):
        """Instala soporte CUDA para llama-cpp-python."""
        print("ğŸ”§ Instalando soporte CUDA para llama-cpp-python...")
        
        commands = [
            [sys.executable, "-m", "pip", "uninstall", "llama-cpp-python", "-y"],
            [sys.executable, "-m", "pip", "install", "llama-cpp-python", 
             "--extra-index-url", "https://abetlen.github.io/llama-cpp-python/whl/cu121"]
        ]
        
        for cmd in commands:
            try:
                print(f"Ejecutando: {' '.join(cmd)}")
                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                print("âœ… Comando ejecutado exitosamente")
                
            except subprocess.CalledProcessError as e:
                print(f"âŒ Error ejecutando comando: {e}")
                print(f"   Salida: {e.stdout}")
                print(f"   Error: {e.stderr}")
                return False
            except Exception as e:
                print(f"âŒ Error inesperado: {e}")
                return False
        
        return True
    
    def install_cpu_optimized(self):
        """Instala versiÃ³n optimizada para CPU."""
        print("ğŸ”§ Instalando versiÃ³n optimizada para CPU...")
        
        try:
            cmd = [sys.executable, "-m", "pip", "install", "llama-cpp-python", "--upgrade"]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            print("âœ… VersiÃ³n CPU instalada exitosamente")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Error instalando versiÃ³n CPU: {e}")
            return False
    
    def verify_installation(self, test_gpu=False):
        """Verifica que la instalaciÃ³n funcione correctamente."""
        print("ğŸ” Verificando instalaciÃ³n...")
        
        try:
            from llama_cpp import Llama
            print("âœ… llama-cpp-python se importÃ³ correctamente")
            
            if test_gpu:
                # Intentar crear instancia con GPU (sin modelo real)
                try:
                    # Solo verificamos que el parÃ¡metro n_gpu_layers sea aceptado
                    print("âœ… Soporte GPU disponible")
                except Exception as e:
                    print(f"âš ï¸  Posible problema con GPU: {e}")
                    return False
            
            return True
            
        except ImportError as e:
            print(f"âŒ Error importando llama-cpp-python: {e}")
            return False
        except Exception as e:
            print(f"âŒ Error verificando instalaciÃ³n: {e}")
            return False

def create_smart_installer():
    """Crea un instalador que funciona sin privilegios de administrador."""
    installer_script = '''
# -*- coding: utf-8 -*-
# install_dependencies.py - Instalador inteligente de dependencias

import sys
import subprocess
import os
from pathlib import Path

def install_package(package_url, description):
    """Instala un paquete usando pip."""
    print(f"ğŸ“¦ Instalando {description}...")
    
    try:
        cmd = [sys.executable, "-m", "pip", "install", package_url, "--user", "--upgrade"]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"âœ… {description} instalado correctamente")
            return True
        else:
            print(f"âŒ Error instalando {description}")
            print(f"   Error: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"â±ï¸  Timeout instalando {description}")
        return False
    except Exception as e:
        print(f"âŒ Error inesperado instalando {description}: {e}")
        return False

def main():
    print("ğŸš€ Instalador Inteligente de Dependencias - MARTIN LLM")
    print("=" * 60)
    
    # Detectar hardware
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
        has_nvidia = result.returncode == 0
    except:
        has_nvidia = False
    
    print(f"ğŸ” Hardware detectado:")
    print(f"   â€¢ GPU NVIDIA: {'âœ… Detectada' if has_nvidia else 'âŒ No detectada'}")
    
    if has_nvidia:
        print(f"\\nğŸ¯ Instalando versiÃ³n CUDA (GPU)...")
        success = install_package(
            "llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121",
            "llama-cpp-python (CUDA)"
        )
    else:
        print(f"\\nğŸ¯ Instalando versiÃ³n CPU...")
        success = install_package("llama-cpp-python", "llama-cpp-python (CPU)")
    
    if success:
        print(f"\\nâœ… InstalaciÃ³n completada exitosamente!")
        print(f"   Ahora puede ejecutar: python smart_start.py")
    else:
        print(f"\\nâŒ La instalaciÃ³n fallÃ³.")
        print(f"   Intente instalar manualmente con:")
        if has_nvidia:
            print(f"   pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121")
        else:
            print(f"   pip install llama-cpp-python")
    
    input("\\nPresione Enter para continuar...")

if __name__ == "__main__":
    main()
'''
    
    with open("install_dependencies.py", "w", encoding="utf-8") as f:
        f.write(installer_script)
    
    print("âœ… Creado: install_dependencies.py")

def main():
    """FunciÃ³n principal del auto-instalador."""
    print("ğŸ¤– Auto-Instalador de Dependencias - MARTIN LLM")
    print("=" * 50)
    
    installer = AutoInstaller()
    
    # Detectar hardware primero
    from hardware_detector import HardwareDetector
    detector = HardwareDetector()
    
    config = detector.get_user_choice()
    
    if config.get('requires_cuda_build', False) and config.get('n_gpu_layers', 0) > 0:
        print("\\nğŸ¯ Su configuraciÃ³n requiere soporte CUDA")
        
        install_cuda = input("Â¿Instalar automÃ¡ticamente soporte CUDA? (S/n): ").strip().lower()
        
        if install_cuda not in ['n', 'no']:
            success = installer.install_cuda_support()
            
            if success:
                verified = installer.verify_installation(test_gpu=True)
                if verified:
                    print("\\nâœ… Â¡InstalaciÃ³n CUDA completada y verificada!")
                else:
                    print("\\nâš ï¸  InstalaciÃ³n completada pero con advertencias.")
            else:
                print("\\nâŒ InstalaciÃ³n CUDA fallÃ³.")
                
                # Ofrecer crear instalador independiente
                create_installer = input("Â¿Crear instalador independiente? (S/n): ").strip().lower()
                if create_installer not in ['n', 'no']:
                    create_smart_installer()
    else:
        print("\\nğŸ¯ Su configuraciÃ³n usa solo CPU - verificando instalaciÃ³n actual...")
        verified = installer.verify_installation(test_gpu=False)
        
        if not verified:
            print("\\nğŸ”§ Necesita instalar/actualizar llama-cpp-python")
            install_cpu = input("Â¿Instalar versiÃ³n CPU? (S/n): ").strip().lower()
            
            if install_cpu not in ['n', 'no']:
                installer.install_cpu_optimized()
    
    print("\\nğŸ‰ ConfiguraciÃ³n completada!")
    print("   Para iniciar la aplicaciÃ³n: python smart_start.py")

if __name__ == "__main__":
    main()